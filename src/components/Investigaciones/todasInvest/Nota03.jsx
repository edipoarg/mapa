import styles from './TodasInvestigaciones.module.css';

const Nota03 = () => {
return(
<>

<p>“Nunca pensé que me iba a tocar vivir algo así. Me tocó a mí, pero le puede tocar a cualquiera. Fue un error de la máquina”.</p>

<p>Consultado por los medios que se habían apostado en la estación Retiro, Guillermo Federico Ibarrola reflexionaba sobre la pesadilla que vivió durante los seis días anteriores. Un sábado de fines de julio de 2019, en esa misma terminal y tras bajarse del tren que acababa de arribar, policías de la Ciudad Autónoma de Buenos Aires le pidieron el documento y lo instaron a acompañarlos. También le dijeron que quedaría demorado por una causa por robo agravado en Bahía Blanca. Guillermo nunca había estado en esa ciudad del sur de la provincia de Buenos Aires, pero cinco días después de la detención terminó siendo trasladado hasta allí. Según fuentes judiciales, cuando Ibarrola estaba siendo trasladado advirtieron que “había habido un error en el informe policial, que consignó mal el número de documento de la persona buscada”. Recién ahí le sacaron las esposas, le dieron los cordones de sus zapatillas y le ofrecieron café y comida. “Ahí cambió el trato”, dijo al regresar luego de que la fiscal del caso le comprara el pasaje de vuelta para volver a su casa en Ezeiza.</p>

<p>Dos meses antes, Leo Colombo Viña bajó a la estación Callao del Subte B para ir al trabajo. Antes de que el tren llegara a la estación, un oficial de la Policía de la Ciudad se le acercó y le pidió el DNI. Le preguntó si alguna vez había estado detenido y le mostró una alerta que coincidía con su documento. Como trabajador del área de sistemas, Colombo estaba convencido de que se trataba de un “falso positivo”, pero en el teléfono celular del oficial apareció la foto de su DNI y Leo visitó la comisaría durante las siguientes tres horas, tuvo que dejar sus huellas dactilares estampadas, recibió instrucciones del juzgado y volvió a la estación a buscar testigos. Recién ahí pudo retomar sus actividades. Según su propio testimonio, los oficiales lo trataron bien en todo momento y hasta hicieron chistes. Durante el proceso, Leo se enteró de que la persona buscada tenía una causa del año 2002 por robo a mano armada, además de otro nombre, otro apellido y otra fecha de nacimiento. Un pequeño detalle: el que coincidía era el número de documento.</p>

<p>Al menos ocho detenciones erróneas como las descriptas, con experiencias más o menos traumáticas para los damnificados, trascendieron en los medios durante 2019. Todas se dieron en la Ciudad Autónoma de Buenos Aires y compartían una peculiaridad: las alertas habían sido generadas por un sistema capaz de extraer información biométrica de las personas en tiempo real. Mientras caminan por la calle o bajan de un transporte público, miles de ciudadanos son registrados por las cámaras de seguridad del gobierno porteño y, sin saberlo, escudriñados por un software que extrae los datos biométricos de sus rostros y los compara con los de una lista de alrededor de 40 mil prófugos de la justicia denominada Consulta Nacional de Rebeldías y Capturas (CoNaRC). Cuando aparece una coincidencia, el software emite una alarma y el personal policial cercano intercepta al individuo, lo demora y le pide que le muestre su DNI para constatar su identidad. Si la identificación coincide con la persona buscada, el demorado queda a disposición de la justicia. Los casos citados al inicio de la nota correspondían a personas que no figuraban en la lista de prófugos, pero sus números de DNI habían sido ingresados por “errores de carga”.</p>

<h6 className={styles.supan}>Mientras caminan por la calle o bajan de un transporte público, miles de ciudadanos son registrados por las cámaras de seguridad del gobierno porteño y, sin saberlo, escudriñados por un software que extrae los datos biométricos de sus rostros y los compara con los de una lista de 40 mil prófugos de la justicia.</h6>

<h3 className={styles.subTile}>El futuro ya llegó</h3>

<p>El nuevo gadget policial se denomina Sistema de Reconocimiento Facial de Prófugos (SRFP) y comenzó a funcionar el 25 de abril de 2019. En junio de ese año también se inauguró el Centro de Monitoreo Urbano (CMU) de la calle Guzmán, en el barrio de Chacarita, donde se centralizó su operación. El CMU, perteneciente a la Policía de la Ciudad, parece una escenografía sacada de un thriller de espionaje high tech. Hay salas de situación rodeadas de videowalls y un enorme pabellón con varias filas de monitores curvos, donde más de 400 operadores observan la ciudad en tiempo real las 24 horas. Con estética futurista, muros translúcidos y mobiliario gris aluminio es el más grande de Latinoamérica. El 31 de mayo Horacio Rodríguez Larreta anunció orgulloso desde allí, que habían logrado el objetivo de monitorear el 75% del espacio de la Ciudad. En la actualidad monitorea más de 11 mil cámaras distribuidas por toda la urbe. De ellas, 9.500 pertenecen al Ministerio de Seguridad porteño. Un 80% cuentan con resolución 4K, lo que permite aplicar el software de reconocimiento facial con eficiencia. Por un limitante de licenciamiento de ese software, el gobierno solo puede escanear 300 cámaras en simultáneo, aunque puede ir rotando por diferentes zonas de la ciudad.</p>

<p>La provisión del SRFP se realizó por contratación directa a la misma empresa que provee la infraestructura del sistema de videovigilancia porteño, Danaide S.A., firma mencionada por Cristina Fernández de Kirchner en 2018 cuando dos de sus operarios intentaban colocar tres cámaras frente a su domicilio. Según el periodista especializado Dave Gershgorn, el componente del software utilizado para el reconocimiento facial habría sido desarrollado por la empresa rusa NtechLab. El sistema funcionó durante poco más de un año, pero apenas comenzada la pandemia la obligatoriedad del uso de barbijos y tapabocas que cubren parte de la cara forzó la interrupción de su empleo.</p>

<p>Según el gobierno de la CABA, la utilización del sistema fue un éxito y desde su puesta en marcha 1.695 personas fueron identificadas y puestas a disposición de la Justicia. Muchas de ellas terminaron detenidas por delitos graves. Las autoridades también reconocen al menos unas 450 identificaciones sin efecto (órdenes de captura no vigentes que sin embargo no fueron dadas de baja en el listado de prófugos) y la emisión de más de 3.000 alertas, lo que indica un alto número de falsos positivos. Vale aclarar que en la lista de la CoNaRC la justicia incluye toda clase de rebeldías, inclusive testigos que no se han presentado a declarar y no pueden ser ubicados. Así, gran parte de las identificaciones positivas concluyen en una notificación del juzgado.</p>

<p>En el plano legal, la Resolución 398/19 sustentó la activación del SRFP. En octubre de 2020, sin mucho debate, la Legislatura aprobó modificaciones a la Ley de Seguridad Pública que reguló y avaló el uso del reconocimiento facial. La norma contó con los votos del oficialismo porteño y aliados, pero el proyecto había sido presentado por Claudia Neira, legisladora del Frente de Todos, quien finalmente votó en contra de su propia propuesta. Este dato sirve para entender cómo la implementación de políticas públicas controvertidas con respecto al uso y la extracción de datos biométricos de la población atraviesa a todas las fuerzas políticas. Cabe recordar que la base de datos masiva del Estado, el Sistema Federal de Identificación Biométrica para la Seguridad (SIBIOS), fue una iniciativa del kirchnerismo aprobada en 2011.</p>

<h6 className={styles.span}>La norma contó con los votos del oficialismo porteño, pero el proyecto había sido presentado por Claudia Neira, legisladora del Frente de Todos, quien finalmente votó en contra de su propia propuesta. la implementación de políticas públicas controvertidas con respecto al uso y la extracción de datos biométricos de la población atraviesa a todas las fuerzas políticas.</h6>

<h3 className={styles.subTile}>Portación de cara</h3>

<p>Durante 2019 varias ONGs presentaron pedidos de acceso a la información para obtener datos sobre el SRFP y gran parte de lo que sabemos sobre su funcionamiento proviene de esas solicitudes. La Asociación por los Derechos Civiles (ADC) presentó un reclamo por inconstitucionalidad que fue rechazado por el Tribunal Superior porteño en abril de 2022. También hubo un recurso de amparo interpuesto por el Observatorio de Derecho Informático Argentino (ODIA), acompañado por la Asociación Civil por la Igualdad y la Justicia (ACIJ), el Centro de Estudios Legales y Sociales (CELS) y la fundación Vía Libre, entre otras, que llevó a que el juez porteño Roberto Gallardo determinara la suspensión del uso del sistema en abril de 2022 como medida precautoria.</p>

<p>La disposición del Juez Gallardo, que cuenta con un largo historial de fallos incómodos para el gobierno de la CABA, fue noticia en todos los medios y volvió a poner sobre el tapete el debate sobre la aplicación de tecnologías de identificación biométrica a escala masiva en Argentina. En las provincias de Salta, Córdoba, Santa Fe y Mendoza también se han implementado, o estudian implementar, sistemas semejantes al porteño. Una de las principales críticas realizadas a este tipo de tecnologías se relaciona con el uso que hace de los datos biométricos -entre los que están los de la forma de la cara-, que se extraen en el espacio público a miles de personas sin su autorización o conocimiento. En ese sentido, el Relator Especial de las Naciones Unidas sobre el derecho a la privacidad, Joseph Cannataci, en una visita oficial a la Argentina durante 2019, puso en duda la “proporcionalidad de instalar una tecnología con graves implicaciones para la privacidad para buscar en una lista de 46 mil personas que actualmente incluye a menores y delitos no graves y que no se actualice y compruebe con cuidado su exactitud”.</p>

<p>Los sistemas de reconocimiento facial, al igual que muchos otros métodos de identificación y control de individuos, comienzan aplicándose en situaciones excepcionales y a grupos limitados, para extenderse luego a la población general. Los primeros usos se llevaron a cabo en las cámaras de seguridad de los aeropuertos “calientes” (con alta circulación de sospechosos), como consecuencia de las medidas de excepción posteriores a los atentados del 11 de septiembre. En cuanto la videovigilancia se naturalizó en las grandes capitales y con cámaras de alta resolución, el uso del reconocimiento facial masivo pasó a ser una posibilidad concreta y la excepción se convirtió en regla. Sin embargo, hoy en día existe un alto nivel de controversia en todo el mundo. Ciudades como San Francisco, Oakland o Portland en Estados Unidos prohibieron el uso del reconocimiento facial aplicado a la población a través de cámaras de vigilancia. Alemania también, y el Parlamento Europeo ha clasificado estas tecnologías como un riesgo inaceptable cuando es aplicada de forma masiva y en tiempo real a la población.</p>

<h6 className={styles.span}>Los primeros usos se llevaron a cabo los aeropuertos “calientes” (con alta circulación de sospechosos), como consecuencia de las medidas de excepción posteriores a los atentados del 11 de septiembre. en cuanto la videovigilancia se naturalizó en las grandes capitales, el reconocimiento facial masivo pasó a ser una posibilidad concreta y la excepción se convirtió en regla. </h6>

<h3 className={styles.subTile}>Olfato policial 4.0</h3>

<p>Los sesgos merecen un apartado especial: se ha probado que la tecnología de Inteligencia Artificial (IA) que se utiliza para realizar la identificación de rostros hace diferencias según raza o edad, ya que los datasets (enormes conjuntos de fotos de caras reales) que se usan para su “entrenamiento” no tienen un origen diverso sino más bien solo de adultos y caucásicos. Entonces, la efectividad del reconocimiento variará según la etnia o edad, generando segmentos de la población más expuestos que otros a la identificación errónea. No hace falta aclarar que esos segmentos de la población también son los más vulnerables a la violencia institucional por parte de las fuerzas de seguridad.</p>

<p>Consultado por crisis, Rodrigo Iglesias, abogado de ODIA y apoderado de la causa que consiguió la suspensión del SRFP, sostiene que el gobierno de la ciudad “contrató un sistema racista”. Según él, el gran problema es que todos los sistemas de identificación biométrica alrededor del mundo tienen sesgos raciales: “No protegen a las minorías, las discriminan y cuando modifican la ley de seguridad pública implementan no solo el sistema de identificación biométrica de prófugos sino un sistema de prevención del delito que no sabemos cómo funciona, o cómo va a ser el tratamiento de datos personales”. Iglesias mismo participó de un análisis de reconocimiento facial: “Me pusieron a mí y me detecta con un 97% de efectividad. Lo pusimos a Alphonse Tchami (exfutbolista) y lo confunde con una sombra. Son los mismos sistemas, lo único que va haciendo la Inteligencia Artificial es que va tomando imágenes y mejorándose todo el tiempo, pero esa mejora es mala porque cada vez que aprende, genera un mayor sesgo racial”. Cabe aclarar que el mismo sistema no reconoce a las personas de ascendencia asiática, mientras que a los colorados “les clava un 98 o 99 por ciento”.</p>

<p>El fallo de Gallardo se fundamenta en la falta de una evaluación previa de su impacto en la privacidad y protección de datos de los ciudadanos, en las falencias de la lista del CoNaRC, en la falta de auditorías y mecanismos de control sobre el desempeño del SRFP y en un llamativo exceso de consultas biométricas que necesita de una explicación más detallada.</p>

<h6 className={styles.span}>“Me pusieron a mí y me detecta con un 97% de efectividad. lo pusimos a alphonse tchami (exfutbolista) y lo confunde con una sombra. cabe aclarar que el mismo sistema no reconoce a los chinos, mientras que a los colorados les clava un 98 o 99 por ciento”.</h6>

<h3 className={styles.subTile}>Fiesta de datos</h3>

<p>Para obtener las caras de las personas buscadas por la justicia listadas en la CoNaRC, el Sistema de Reconocimiento Facial de Prófugos realiza una solicitud automática a la base de datos del Registro Nacional de las Personas (RENAPER), un organismo autárquico dependiente del Ministerio del Interior de la Nación que desde el establecimiento del SIBIOS centraliza y provee a los diferentes organismos los datos biométricos de toda la población. Existe un convenio entre el RENAPER y el Ministerio de Justicia y Seguridad de la CABA para proveer esta información y, según consta en el documento, debe estar limitada a las funciones del sistema de reconocimiento facial. Por lo tanto, el número de consultas debería ser congruente con los 40 mil prófugos buscados. Sin embargo, cuando el Juez Gallardo solicitó al Renaper la lista de todas las consultas realizadas desde el gobierno porteño entre abril de 2019 y marzo de 2022, se encontró con un número exorbitante: 9.900.282 de solicitudes correspondientes a siete millones de personas, entre las cuales aparecieron numerosos políticos, empresarios y periodistas.</p>

<p>No existe una respuesta clara por parte de las autoridades de CABA sobre cuál es el objeto de estas consultas, ni bajo qué convenio se realizaban.  También es llamativo el número de solicitudes para algunas figuras de la política. Cristina Fernández de Kirchner, por ejemplo, tuvo 225 pedidos, lo que equivale a casi una consulta por día en determinados lapsos temporales. Otros casos con peticiones numerosas son Alberto Fernández, Presidente de la Nación, Axel Kicillof, Gobernador de la provincia de Buenos Aires, el diputado Javier Milei, o la exministra de seguridad Patricia Bullrich.</p>

<p>Para Iglesias “hay un montón de indicios de que algo raro pasa, no sabemos si es espionaje, si es un atentado contra la democracia, o una utilización desmedida por parte de la fuerza y nada más”. Luego agrega: “Hay una sola conexión lógica entre Renaper y el Ministerio, hay un solo cable, un solo nodo, va de ahí hasta allá. Fin. Y los oficiales tienen una app de los policías de la Ciudad y cuando vos hacés el análisis de las consultas que hicieron, te dan pico los fines de semana”. ¿Acaso la fiesta de consultas podría tener una motivación lúdica?</p>

<h6 className={styles.span}>También es llamativo el número de solicitudes para algunas figuras de la política. cristina fernández de kirchner, por ejemplo, tuvo 225 pedidos, lo que equivale a casi una consulta por día en determinados lapsos temporales. otros casos con peticiones numerosas son alberto fernández, presidente de la nación, axel kicillof, gobernador de la provincia de buenos aires, el diputado javier milei, o la exministra de seguridad patricia bullrich.</h6>

<h3 className={styles.subTile}>Ciudad de cromañon</h3>

<p>Es que el SRFP también permitía la realización de consultas manuales por parte de los operadores del Centro de Monitoreo Urbano, es decir, sin que haya un disparador de la alarma de coincidencia biométrica. Esos 400 operadores que monitorean las cámaras de seguridad porteñas pueden, según su criterio, buscar en la base de datos de Renaper a cualquier persona que aparezca en las imágenes captadas por las cámaras.</p>

<p>En un escenario en el que el software emite un alerta, el oficial puede consultar los datos personales de la persona demorada, incluido su domicilio. Durante el proceso, el Sistema de Monitoreo Integral Urbano (SMIU) y el Sistema de Seguridad Ciudadana (SISC), que funcionan en paralelo, registran todos los datos y grabaciones en un servidor alojado en un Data Center. El Gobierno de la Ciudad reconoce que al menos una vez hubo una filtración masiva de datos, aunque no precisa cuántas personas se vieron afectadas ni las consecuencias. Los datos no eran sensibles y se dieron de baja. También aseguran que la actualización de los sistemas no puede realizarse a distancia y se hace cada tres meses, en tanto que la base de datos de Renaper se actualiza semanalmente. Según Iglesias “el gobierno utiliza a Renaper para hacer consultas masivas, nosotros no sabemos cuándo se actualiza, cuándo se dejó de hacer consultas, si se están haciendo o no, si hay un protocolo. Eso no lo sabemos porque hay que pedir un informe para saber cuántas consultas se hicieron”.</p>

<p>El gobierno de la ciudad afirma que las actualizaciones del software de Renaper y las consultas se hacen semanalmente y que no hubo consecuencias negativas para la población a raíz de la filtración de datos masiva que reconoce. Sin embargo, no brindan detalles sobre la cantidad de consultas, el objeto o el protocolo de actuación. </p>

<p>Además de las consultas manuales, existen también las automáticas, generadas por el SRFP cuando se produce una coincidencia biométrica con una persona buscada. Estas consultas son las que se esperarían encontrar en los registros y son aquellas que justifican la existencia del sistema. No obstante, la cantidad de solicitudes manuales supera en gran medida a las automáticas. En la base de datos que Gallardo solicitó al Renaper figura, por ejemplo, que de los 1.695 identificados y puestos a disposición de la Justicia, solo el 12% proviene de alertas generadas por el sistema, mientras que el 88% restante fue producto de consultas manuales.</p>

<p>¿A dónde se dirige la tecnología de control social en Argentina? ¿Cuál es el fin último del uso de tecnologías de identificación biométrica? ¿Qué grado de control sobre la población está dispuesto a aceptar el ciudadano medio en pos de una mayor seguridad? ¿Cuál es la respuesta de las autoridades al creciente reclamo de mayor seguridad por parte de la ciudadanía?</p>

<p>En una sociedad del control, la vigilancia no se manifiesta solo en la cantidad de cámaras instaladas en la vía pública sino en la posibilidad de ser monitoreado en tiempo real en cualquier momento del día. La excepción es la regla. Lo que se requiere es la aplicación de tecnologías de identificación biométrica a escala masiva, en el espacio público, y el cruce de información con bases de datos del Estado, muchas veces construidas sin el consentimiento de los ciudadanos. La necesidad de seguridad se ha convertido en la principal justificación para la implementación de estas medidas. Seguridad entendida como la certeza de que no se sufrirá ningún daño, en un sentido amplio que incluye la integridad física, el patrimonio y la tranquilidad psíquica.</p>

<p>En la búsqueda de esa seguridad se justifican las excepciones a la privacidad y a la protección de datos. Es la máxima según la cual “si no tengo nada que esconder, no tengo nada que temer”. Pero esa máxima esconde la paradoja según la cual para no temer es necesario no tener nada que esconder y para no tener nada que esconder es necesario no temer. Además, ignora la dimensión colectiva del derecho a la privacidad. El impacto del reconocimiento facial no se agota en la afectación a la privacidad de un individuo, sino que afecta a toda la sociedad.</p>

<p>En la búsqueda de esa seguridad se justifican las excepciones a la privacidad y a la protección de datos. Es la máxima según la cual “si no tengo nada que esconder, no tengo nada que temer”.</p>

<p>La seguridad, la transparencia y el acceso a la información son principios fundamentales en una sociedad democrática. La posibilidad de ser vigilado en todo momento no parece ser un buen precio a pagar por una mayor seguridad, si conlleva la pérdida de la privacidad y la protección de los datos personales. En ese sentido, la decisión del Juez Gallardo de suspender el SRFP puede considerarse un triunfo en la defensa de esos principios. Sin embargo, la suspensión de una medida gubernamental por parte de la justicia no garantiza que esa medida no se vuelva a implementar en el futuro. Por lo tanto, es necesario seguir debatiendo y reflexionando sobre los límites del control social y la vigilancia en una sociedad democrática.</p>
</>
);
}

export default Nota03;